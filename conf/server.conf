# Kafka集群消费指令集
[Kafka_Cluster]
# KAFKA地址和端口或KAFKA集群地址和端口，例如192.168.100.11:9092
BOOTSTRAP_SERVERS = KAFKA_IP:KAFKA_PORT
# 消费者组ID
GROUP_ID = adhoc
# 始终消费Kafka中的最新数据
AUTO_OFFSET_RESET = latest
# Kafka创建的topic名称
TOPIC = adhoc2

# Zabbix监控exec-engine 发送心跳包
[Zabbix]
# zabbix的server端或proxy端IP
IP = ZABBIX_SERVER_IP
# Zabbix端口
ZABBIX_PORT = 10051
# 自定义trapper监控项
ITEM = exec.engine.ping

# 执行结果存储
[Fil_EXEC_MySQL]
# MySQL地址
IP = MySQL_IP
# MySQL端口
PORT = 3306
# 数据库名称
DATABASE = execute_engine
# 数据库用户
USER = root
# 数据库密码(加密后的密码：加密使用fil-execute-engine/utils/encrypt_decrypt.py脚本对密码进行加密和解密)
PASSWORD = 630898019a777c984645f0b01d3fe3d4ee2bacdc1aec34995218ff8823978401

[Ansible]
# 执行任务时，ssh连接用户
SSH_USER = admin
# 执行任务时，ssh连接用户的密码
SSH_PASSWORD = admin
# 执行任务时，ssh连接用户的sudo密码
SSH_SUDO_PASSWORD = admin

# 进程执行等待时间
[Data_Send]
# 心跳信息上报时间间隔
ZABBIX = 10
# 消费者消费的时间间隔
EXEC = 1

# Distribute的IP地址
DISTRIBUTE_IP = Distribute_ip